{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = 500 # number of batches of time series\n",
    "f_horizon = 250 # forecast horizon, n timesteps into the future\n",
    "periods = 6000 + f_horizon\n",
    "\n",
    "np.random.seed(111)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "\n",
    "ext_val = -10*np.pi\n",
    "rads = np.linspace(start=-ext_val, stop=ext_val, num=periods)\n",
    "\n",
    "rads_rand = np.linspace(start=-5*ext_val, stop=5*ext_val, num=periods)\n",
    "rads_rand = np.sin(rads_rand) * np.random.uniform(0.8, 1, size=periods)\n",
    "rads_rand *= 0.8\n",
    "plt.plot(rads_rand)\n",
    "plt.show()\n",
    "\n",
    "rand = np.random.uniform(-1, 1, size=periods).cumsum()\n",
    "rand = rand / max(abs(rand)) #* 4\n",
    "#rads = np.add(rads, rand)\n",
    "#print(len(rads))\n",
    "plt.plot(rand)\n",
    "plt.show()\n",
    "#ts = pd.Series(np.sin(rads) + rand + rads_rand, rads)#.cumsum()\n",
    "#ts = pd.Series(np.sin(rads), rads)#.cumsum()\n",
    "\n",
    "ts = pd.Series(rand)#.cumsum()\n",
    "\n",
    "\n",
    "ts.plot(c='b', title='Example Time Series')\n",
    "plt.show()\n",
    "ts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break data up into array that we can make batches of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = np.array(ts)\n",
    "\n",
    "ts_len = len(TS) - batch_length\n",
    "\n",
    "# input data\n",
    "x_data = TS[:(ts_len - ts_len % batch_length)]\n",
    "print(len(x_data))\n",
    "# get the time x values as bathces\n",
    "x_batches = x_data.reshape(-1, batch_length, 1)\n",
    "\n",
    "# do the same with the y values, but shift the values by how long into future we want to predict values\n",
    "# y values are the true sequence coming after the x sequences\n",
    "y_data = TS[f_horizon:(ts_len - (ts_len % batch_length)) + f_horizon]\n",
    "print(len(y_data))\n",
    "y_batches = y_data.reshape(-1, batch_length, 1)\n",
    "\n",
    "print('y batches should be shifted by f_horizon values compared to x batches')\n",
    "\n",
    "print('x_batches')\n",
    "print(x_batches.shape)\n",
    "#print(x_batches[0:2])\n",
    "\n",
    "print('y_batches')\n",
    "print(y_batches.shape)\n",
    "#print(y_batches[0:2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x_batches, y_batches, train_proportion=0.8):\n",
    "    num_batches = len(x_batches)\n",
    "    num_train_batches = int(train_proportion * num_batches)\n",
    "    \n",
    "    X_train = x_batches[:num_train_batches]\n",
    "    Y_train = y_batches[:num_train_batches]\n",
    "    \n",
    "    X_test = x_batches[num_train_batches:]\n",
    "    Y_test = y_batches[num_train_batches:]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "train_proportion = 0.8\n",
    "X_train, Y_train, X_test, Y_test = split_data(x_batches, y_batches, train_proportion)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensorflow graph for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Reset previous running graphs\n",
    "\n",
    "inputs = 1\n",
    "outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, batch_length, inputs])\n",
    "y = tf.placeholder(tf.float32, [None, batch_length, outputs])\n",
    "\n",
    "hidden_units = 512\n",
    "\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_units, activation=tf.nn.relu)\n",
    "rnn_output, states = tf.nn.dynamic_rnn(rnn_cell, X, dtype=tf.float32)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "stacked_rnn_output = tf.reshape(rnn_output, [-1, hidden_units])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_output, outputs)\n",
    "out = tf.reshape(stacked_outputs, [-1, batch_length, outputs])\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(out - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    global_step = tf.train.create_global_step()\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "    with tf.train.MonitoredSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        #for ep in range(epochs):\n",
    "            sess.run(training_op, feed_dict={X:X_train, y:Y_train})\n",
    "\n",
    "        if ep % 100 == 0:\n",
    "            mse = sess.run(loss, feed_dict={X:X_test, y:Y_test})\n",
    "            print(ep, '\\tMSE:', mse)\n",
    "    y_pred_train = sess.run(out, feed_dict={X:X_train})\n",
    "    y_pred_test = sess.run(out, feed_dict={X:X_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Forecast vs actual', fontsize=14)\n",
    "#plt.plot(pd.Series(np.ravel(Y_train)), 'y', markersize=10, label='actual')\n",
    "#plt.plot(pd.Series(np.ravel(y_pred_train)), 'g', markersize=10, label='actual')\n",
    "\n",
    "plt.plot(pd.Series(np.ravel(Y_test)), 'b', markersize=10, label='actual')\n",
    "plt.plot(pd.Series(np.ravel(y_pred_test)), 'r', markersize=10, label='forecast')\n",
    "\n",
    "\n",
    "xcoords = np.array([x for x in range(0, len(np.ravel(Y_test)), batch_length)])\n",
    "xcoords2 = xcoords + batch_length - f_horizon\n",
    "\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='k')\n",
    "\n",
    "for xc in xcoords2:\n",
    "    plt.axvline(x=xc, color='g')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('time periods')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
