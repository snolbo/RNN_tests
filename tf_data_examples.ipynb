{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_34:0\", shape=(10, 2), dtype=float32)\n",
      "001, x:[11.529  8.587  9.479  9.592], y:[9. 5.] \n",
      "002, x:[ 8.637  9.138  8.935 10.369], y:[3. 2.] \n",
      "003, x:[ 9.46  10.829 10.699 10.724], y:[1. 7.] \n",
      "004, x:[ 8.713 10.339 11.304 10.746], y:[0. 6.] \n",
      "005, x:[10.623 10.578 10.143  9.266], y:[8. 4.] \n",
      "006, x:[ 8.935 10.369 10.623 10.578], y:[2. 8.] \n",
      "007, x:[ 8.713 10.339 10.699 10.724], y:[0. 7.] \n",
      "008, x:[9.479 9.592 8.637 9.138], y:[5. 3.] \n",
      "009, x:[10.143  9.266 11.529  8.587], y:[4. 9.] \n",
      "010, x:[ 9.46  10.829 11.304 10.746], y:[1. 6.] \n",
      "011, x:[ 8.637  9.138  9.46  10.829], y:[3. 1.] \n",
      "012, x:[10.623 10.578 11.304 10.746], y:[8. 6.] \n",
      "013, x:[10.143  9.266  9.479  9.592], y:[4. 5.] \n",
      "014, x:[ 8.935 10.369 10.699 10.724], y:[2. 7.] \n",
      "015, x:[11.529  8.587  8.713 10.339], y:[9. 0.] \n",
      "016, x:[10.699 10.724 11.529  8.587], y:[7. 9.] \n",
      "017, x:[10.623 10.578 10.143  9.266], y:[8. 4.] \n",
      "018, x:[11.304 10.746  9.46  10.829], y:[6. 1.] \n",
      "019, x:[ 8.713 10.339  8.935 10.369], y:[0. 2.] \n",
      "020, x:[9.479 9.592 8.637 9.138], y:[5. 3.] \n",
      "021, x:[10.623 10.578  8.935 10.369], y:[8. 2.] \n",
      "022, x:[ 8.713 10.339  9.46  10.829], y:[0. 1.] \n",
      "023, x:[11.304 10.746  9.479  9.592], y:[6. 5.] \n",
      "024, x:[ 8.637  9.138 10.699 10.724], y:[3. 7.] \n",
      "025, x:[11.529  8.587 10.143  9.266], y:[9. 4.] \n",
      "end of dataset\n",
      "occurrence array: [5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# A typical TensorFlow training input pipeline can be framed as an ETL process:\n",
    "\n",
    "# Extract: Read data from persistent storage -- either local (e.g. HDD or SSD) or remote (e.g. GCS or HDFS).\n",
    "\n",
    "# Transform: Use CPU cores to parse and perform preprocessing operations on the data such as image decompression, \n",
    "#     data augmentation transformations (such as random crop, flips, and color distortions), shuffling, and batching.\n",
    "\n",
    "# Load: Load the transformed data onto the accelerator device(s) (for example, GPU(s) or TPU(s)) that execute the \n",
    "#     machine learning model.\n",
    "\n",
    "\n",
    "# The tf.data API provides users with building blocks to design input pipelines that effectively utilize the CPU, \n",
    "#     optimizing each step of the ETL process.\n",
    "\n",
    "\n",
    "\n",
    "# Pipelining overlaps the preprocessing and model execution of a training step. While the accelerator is performing \n",
    "#     training step N, the CPU is preparing the data for step N+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=150, precision=3, suppress=True)\n",
    "\n",
    "\n",
    "M = 10\n",
    "d = 2\n",
    "# samples\n",
    "X = tf.constant(np.random.randn(M, d), 'float32')\n",
    "# ids of samples, say each sample have different id\n",
    "Y = tf.constant(np.expand_dims(np.random.permutation(M), 1), 'float32')\n",
    "\n",
    "dataset_items = (X,Y)\n",
    "# first dimensions must match\n",
    "# also they should be at least 2 rank\n",
    "first_dims = [item.shape.as_list()[0] for item in dataset_items]\n",
    "assert np.all(np.equal(first_dims, first_dims[0]))\n",
    "\n",
    "batch_size = 2\n",
    "n_epochs = 5\n",
    "\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "\n",
    "# buffer_size: A tf.int64 scalar tf.Tensor, representing the number of elements from this \n",
    "# dataset from which the new dataset will sample. Defaults to reshuffle each iteration over dataset\n",
    "dataset = dataset.shuffle(buffer_size=M)\n",
    "\n",
    "\n",
    "## Doing pararell preprocessing of data using map function\n",
    "def func(X, Y):\n",
    "  X += 10\n",
    "  return X, Y\n",
    "\n",
    "dataset = dataset.map(func)\n",
    "\n",
    "\n",
    "#dataset = dataset.map(map_func=parse_fn, num_parallel_calls=FLAGS.num_parallel_calls)\n",
    "#dataset = dataset.batch(batch_size=FLAGS.batch_size)\n",
    "\n",
    "# If batch size is large, fuse map and batch function\n",
    "# dataset = dataset.apply(\n",
    "#             tf.contrib.data.map_and_batch(map_func=parse_fn, batch_size=FLAGS.batch_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combines consecutive elements of this dataset into batches.\n",
    "# If your program depends on the batches having the same outer dimension, you should set the drop_remainder \n",
    "# argument to True to prevent the smaller batch from being produced.\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #The simplest way to iterate over a dataset in multiple epochs is to use the Dataset.repeat() transformation\n",
    "# # Applying the Dataset.repeat() transformation with no arguments will repeat the input indefinitely\n",
    "# dataset = dataset.repeat(n_epochs)\n",
    "\n",
    "\n",
    "# The tf.data API provides a software pipelining mechanism through the tf.data.Dataset.prefetch transformation, which\n",
    "# can be used to decouple the time data is produced from the time it is consumed. To achieve the pipelining effect \n",
    "# you can add prefetch(1) as the final transformation to your dataset pipeline (or prefetch(n) if a single training \n",
    "# step consumes n elements).\n",
    "\n",
    "dataset = dataset.prefetch(2)\n",
    "\n",
    "\n",
    "\n",
    "# training_iterator = training_dataset.make_one_shot_iterator()\n",
    "# validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "# next_train_batch = training_iterator.get_next()\n",
    "# next_test_batch = validation_iterator.get_next()\n",
    "\n",
    "# sess.run(training_iterator.initializer)\n",
    "\n",
    "\n",
    "# while True:\n",
    "#   for _ in range(200):\n",
    "#     sess.run(next_train_batch)\n",
    "\n",
    "#   # Run one pass over the validation dataset.\n",
    "#   sess.run(validation_iterator.initializer)\n",
    "#   for _ in range(50):\n",
    "#     sess.run(next_test_batch)\n",
    "\n",
    "\n",
    "dataset_iterator = dataset.make_initializable_iterator()\n",
    "next_batch = dataset_iterator.get_next()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(dataset_iterator.initializer)\n",
    "\n",
    "occurrence = np.zeros([M], 'int32')\n",
    "\n",
    "it = 0\n",
    "\n",
    "\n",
    "# Compute for n epochs.\n",
    "for _ in range(1):\n",
    "    sess.run(dataset_iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            it += 1\n",
    "            xb, yb = sess.run(next_batch)\n",
    "            occurrence[np.int32(yb)] += 1\n",
    "            print('%03d, x:%s, y:%s ' % (it, str(xb.ravel()), str(yb.ravel())))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('end of dataset')\n",
    "            break\n",
    "\n",
    "   \n",
    "sess.close()\n",
    "\n",
    "print('occurrence array:', occurrence) # all entries should be M, indicating each sample is fetched M times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links to tf.data and input pipeline performance\n",
    "https://www.tensorflow.org/guide/datasets\n",
    "https://www.tensorflow.org/performance/datasets_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING AND RESTORING ITERATOR\n",
    "# Create saveable object from iterator.\n",
    "# saveable = tf.contrib.data.make_saveable_from_iterator(iterator)\n",
    "\n",
    "# # Save the iterator state by adding it to the saveable objects collection.\n",
    "# tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "\n",
    "#   if should_checkpoint:\n",
    "#     saver.save(path_to_checkpoint)\n",
    "\n",
    "# # Restore the iterator state.\n",
    "# with tf.Session() as sess:\n",
    "#   saver.restore(sess, path_to_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/data/training_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf3fb514b846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the training data into two NumPy arrays, for example using `np.load()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/var/data/training_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/var/data/training_data.npy'"
     ]
    }
   ],
   "source": [
    "# NUMPY arrays\n",
    "\n",
    "\n",
    "# Load the training data into two NumPy arrays, for example using `np.load()`.\n",
    "with np.load(\"/var/data/training_data.npy\") as data:\n",
    "  features = data[\"features\"]\n",
    "  labels = data[\"labels\"]\n",
    "\n",
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# If all of your input data fit in memory, the simplest way to create a Dataset from them is to convert them to \n",
    "# tf.Tensor objects and use Dataset.from_tensor_slices().\n",
    "\n",
    "# Load the training data into two NumPy arrays, for example using `np.load()`.\n",
    "with np.load(\"/var/data/training_data.npy\") as data:\n",
    "  features = data[\"features\"]\n",
    "  labels = data[\"labels\"]\n",
    "\n",
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "features_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "# [Other transformations on `dataset`...]\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features,\n",
    "                                          labels_placeholder: labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV DATA\n",
    "# Creates a dataset that reads all of the records from two CSV files, each with\n",
    "# eight float columns\n",
    "filenames = [\"/var/data/file1.csv\", \"/var/data/file2.csv\"]\n",
    "record_defaults = [tf.float32] * 8   # Eight required float columns\n",
    "dataset = tf.contrib.data.CsvDataset(filenames, record_defaults)\n",
    "\n",
    "# Creates a dataset that reads all of the records from two CSV files, each with\n",
    "# four float columns which may have missing values\n",
    "record_defaults = [[0.0]] * 8\n",
    "dataset = tf.contrib.data.CsvDataset(filenames, record_defaults)\n",
    "\n",
    "# Creates a dataset that reads all of the records from two CSV files with\n",
    "# headers, extracting float data from columns 2 and 4.\n",
    "record_defaults = [[0.0]] * 2  # Only provide defaults for the selected columns\n",
    "dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[2,4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preproceccing with Sataset.map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: ['/var/data/image1.jpg', '/var/data/image2.jpg', Ellipsis]. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got Ellipsis",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8c18ab2f2523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# A vector of filenames.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/var/data/image1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/var/data/image2.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# `labels[i]` is the label for the image in `filenames[i].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    194\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    523\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    524\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: ['/var/data/image1.jpg', '/var/data/image2.jpg', Ellipsis]. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "def _parse_function(filename, label):\n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = tf.image.decode_jpeg(image_string)\n",
    "  image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "  return image_resized, label\n",
    "\n",
    "# A vector of filenames.\n",
    "filenames = tf.constant([\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...])\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i].\n",
    "labels = tf.constant([0, 37, ...])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "dataset = dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cc81cd33d1de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnext_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "print(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\n",
    "print(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\n",
    "print(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to receive a signal at the end of each epoch, you can write a training loop that catches the \n",
    "# tf.errors.OutOfRangeError at the end of a dataset. At that point you might collect some statistics \n",
    "# (e.g. the validation error) for the epoch.\n",
    "\n",
    "filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(...)\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Compute for 100 epochs.\n",
    "for _ in range(100):\n",
    "  sess.run(iterator.initializer)\n",
    "  while True:\n",
    "    try:\n",
    "      sess.run(next_element)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      break\n",
    "\n",
    "  # [Perform end-of-epoch calculations here.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
